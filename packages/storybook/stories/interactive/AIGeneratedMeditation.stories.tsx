import type { Meta, StoryObj } from '@storybook/react-vite';
import { QueryClient, QueryClientProvider } from '@tanstack/react-query';
import type { ReactElement } from 'react';
import { fn, expect, userEvent, within } from 'storybook/test';

import type {
  AIGeneratedMeditationActivityData,
  AIMeditationVoice,
} from '@/components/GuidedMeditation';
import {
  AIGeneratedMeditation,
  VoiceSelector,
  MeditationVisual,
} from '@/components/GuidedMeditation';

// Create a client for Storybook stories
const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: false,
      staleTime: Infinity,
    },
  },
});

// Mock voices for stories - using real OpenAI voice IDs
const MOCK_VOICES: AIMeditationVoice[] = [
  {
    id: 'marin',
    name: 'Marin',
    description: 'Warm, calm voice with excellent clarity (recommended)',
    best_for: ['body_scan', 'loving_kindness', 'sleep', 'anxiety_relief'],
    preview_url: null,
  },
  {
    id: 'cedar',
    name: 'Cedar',
    description: 'Deep, grounding voice with natural warmth (recommended)',
    best_for: ['breathing_focus', 'body_scan', 'daily_mindfulness', 'anxiety_relief'],
    preview_url: null,
  },
  {
    id: 'nova',
    name: 'Nova',
    description: 'Warm, calm female voice ideal for meditation',
    best_for: ['body_scan', 'loving_kindness', 'sleep', 'anxiety_relief'],
    preview_url: null,
  },
  {
    id: 'sage',
    name: 'Sage',
    description: 'Gentle, wise voice for reflective practices',
    best_for: ['loving_kindness', 'body_scan', 'anxiety_relief'],
    preview_url: null,
  },
];

// Mock activity data factory
function createMockActivityData(
  overrides: Partial<AIGeneratedMeditationActivityData> = {}
): AIGeneratedMeditationActivityData {
  return {
    type: 'activity',
    activity: 'meditation_ai_generated',
    status: 'ready',
    meditation_id: 'test-meditation-123',
    title: 'Evening Calm',
    meditation_type: 'anxiety_relief',
    duration_minutes: 10,
    script: {
      content: 'Welcome to this personalized meditation. Take a deep breath...',
      word_count: 850,
      estimated_duration_seconds: 600,
    },
    voice: MOCK_VOICES[0],
    generation_context: {
      time_of_day: 'evening',
      primary_intent: 'reduce stress after work',
      memories_used: 3,
      emotional_signals: ['stressed', 'tired'],
    },
    introduction:
      "I've created a personalized meditation just for you, focusing on releasing the stress from your day.",
    ...overrides,
  };
}

/**
 * AI-Generated Meditation component with personalized scripts and OpenAI TTS.
 *
 * Features:
 * - Personalized meditation scripts generated by OpenAI
 * - Voice selection from OpenAI's TTS voices
 * - Audio generated in single API call with text + audio modalities
 * - Before/after mood tracking
 * - Auto-save to meditation library
 */
const meta: Meta<typeof AIGeneratedMeditation> = {
  title: 'Interactive/AIGeneratedMeditation',
  component: AIGeneratedMeditation,
  decorators: [
    (Story): ReactElement => (
      <QueryClientProvider client={queryClient}>
        <Story />
      </QueryClientProvider>
    ),
  ],
  parameters: {
    layout: 'centered',
    backgrounds: { default: 'wellness' },
    docs: {
      description: {
        component: `
AI-generated personalized meditation component that renders inline within the chat.

## Features
- Personalized meditation scripts generated by OpenAI
- Voice selection from OpenAI TTS voices (marin, cedar, nova, etc.)
- Single API call generates both text and audio together
- Context-aware: uses memories, time of day, conversation context
- Before/after mood tracking
- Auto-saves completed meditations to library

## Flow
1. AI generates personalized meditation with OpenAI gpt-4o-mini-audio-preview
2. User confirms voice selection
3. Audio is pre-generated and cached to Supabase Storage
4. Standard playback controls during meditation
5. Mood check and auto-save on completion

## Usage
This component is embedded within chat messages when the AI generates a personalized meditation.
        `,
      },
    },
  },
  args: {
    activityData: createMockActivityData(),
    onComplete: fn(),
    onStop: fn(),
    enableAmbient: false,
  },
};

export default meta;
type Story = StoryObj<typeof AIGeneratedMeditation>;

// ==============================================================================
// Main Component Stories
// ==============================================================================

/**
 * Default AI-generated meditation in ready state.
 * Shows the meditation info card with start button.
 */
export const Default: Story = {
  args: {
    activityData: createMockActivityData(),
  },
};

/**
 * Meditation for anxiety relief.
 * Personalized based on stress signals.
 */
export const AnxietyRelief: Story = {
  args: {
    activityData: createMockActivityData({
      title: 'Stress Release',
      meditation_type: 'anxiety_relief',
      duration_minutes: 10,
      generation_context: {
        time_of_day: 'afternoon',
        primary_intent: 'feeling overwhelmed with work',
        memories_used: 5,
        emotional_signals: ['anxious', 'overwhelmed', 'tense'],
      },
      introduction:
        "I can hear you're feeling overwhelmed. I've created a calming meditation specifically for releasing tension and finding peace.",
    }),
  },
};

/**
 * Body scan meditation.
 * Focus on physical relaxation.
 */
export const BodyScan: Story = {
  args: {
    activityData: createMockActivityData({
      title: 'Full Body Relaxation',
      meditation_type: 'body_scan',
      duration_minutes: 15,
      voice: MOCK_VOICES[1], // Cedar - deep voice for body scan
      generation_context: {
        time_of_day: 'night',
        primary_intent: 'release physical tension',
        memories_used: 2,
        emotional_signals: ['tense', 'tired'],
      },
      introduction:
        "Let's scan through your body and release any tension you're holding. This is a thorough 15-minute practice.",
    }),
  },
};

/**
 * Loving kindness meditation.
 * Focus on self-compassion.
 */
export const LovingKindness: Story = {
  args: {
    activityData: createMockActivityData({
      title: 'Self-Compassion Practice',
      meditation_type: 'loving_kindness',
      duration_minutes: 12,
      voice: MOCK_VOICES[2], // Nova - nurturing voice
      generation_context: {
        time_of_day: 'morning',
        primary_intent: 'self-criticism, need self-compassion',
        memories_used: 4,
        emotional_signals: ['self-critical', 'seeking comfort'],
      },
      introduction:
        "This loving kindness meditation will help you cultivate compassion for yourself. We'll build kindness from the inside out.",
    }),
  },
};

/**
 * Sleep meditation.
 * Evening practice for restful sleep.
 */
export const SleepMeditation: Story = {
  args: {
    activityData: createMockActivityData({
      title: 'Peaceful Sleep Journey',
      meditation_type: 'sleep',
      duration_minutes: 20,
      generation_context: {
        time_of_day: 'night',
        primary_intent: 'prepare for sleep',
        memories_used: 3,
        emotional_signals: ['restless', 'racing thoughts'],
      },
      introduction:
        'As you prepare for sleep, this meditation will guide you into deep relaxation. Get comfortable and let go of the day.',
    }),
  },
};

/**
 * Morning mindfulness.
 * Start the day with intention.
 */
export const MorningMindfulness: Story = {
  args: {
    activityData: createMockActivityData({
      title: 'Morning Intention Setting',
      meditation_type: 'daily_mindfulness',
      duration_minutes: 7,
      generation_context: {
        time_of_day: 'morning',
        primary_intent: 'start day mindfully',
        memories_used: 2,
        emotional_signals: ['refreshed', 'open'],
      },
      introduction:
        "Good morning! Let's set a mindful intention for your day ahead with this brief meditation.",
    }),
  },
};

/**
 * With pre-generated audio URL.
 * Skips streaming, shows ready state directly.
 */
export const WithPreGeneratedAudio: Story = {
  args: {
    activityData: createMockActivityData({
      audio_url: 'https://example.com/meditation.mp3',
    }),
  },
  parameters: {
    docs: {
      description: {
        story: 'When replaying a saved meditation, audio_url is provided and streaming is skipped.',
      },
    },
  },
};

/**
 * With ambient sounds enabled.
 */
export const WithAmbientSounds: Story = {
  args: {
    activityData: createMockActivityData(),
    enableAmbient: true,
  },
  parameters: {
    docs: {
      description: {
        story: 'Meditation with ambient sound mixer enabled for background atmosphere.',
      },
    },
  },
};

/**
 * Without introduction text.
 */
export const NoIntroduction: Story = {
  args: {
    activityData: createMockActivityData({
      introduction: '',
    }),
  },
};

// ==============================================================================
// VoiceSelector Component Stories
// ==============================================================================

/**
 * VoiceSelector component for choosing meditation voice.
 */
export const VoiceSelectorDefault: StoryObj<typeof VoiceSelector> = {
  render: () => (
    <VoiceSelector
      voices={MOCK_VOICES}
      selectedVoiceId={null}
      onSelect={fn()}
      onConfirm={fn()}
      onCancel={fn()}
    />
  ),
  parameters: {
    docs: {
      description: {
        story: 'Voice selection grid with no voice selected initially.',
      },
    },
  },
};

/**
 * VoiceSelector with a voice pre-selected.
 */
export const VoiceSelectorWithSelection: StoryObj<typeof VoiceSelector> = {
  render: () => (
    <VoiceSelector
      voices={MOCK_VOICES}
      selectedVoiceId="marin"
      onSelect={fn()}
      onConfirm={fn()}
      onCancel={fn()}
    />
  ),
  parameters: {
    docs: {
      description: {
        story: 'Voice selector with Marin already selected.',
      },
    },
  },
};

/**
 * VoiceSelector in loading state.
 */
export const VoiceSelectorLoading: StoryObj<typeof VoiceSelector> = {
  render: () => (
    <VoiceSelector
      voices={MOCK_VOICES}
      selectedVoiceId="cedar"
      onSelect={fn()}
      onConfirm={fn()}
      isLoading={true}
    />
  ),
  parameters: {
    docs: {
      description: {
        story: 'Voice selector in loading state after confirmation.',
      },
    },
  },
};

// ==============================================================================
// State Simulation Stories
// ==============================================================================

/**
 * Streaming state simulation.
 * Shows the generating UI with progress bar.
 */
export const StreamingState: Story = {
  render: () => (
    <div
      style={{
        padding: '24px',
        background: 'var(--color-exercise-card)',
        borderRadius: '12px',
        maxWidth: '400px',
      }}
    >
      <p
        style={{ textAlign: 'center', color: 'var(--color-text-secondary)', marginBottom: '16px' }}
      >
        I've created a personalized meditation just for you.
      </p>

      <div style={{ display: 'flex', flexDirection: 'column', alignItems: 'center', gap: '16px' }}>
        <MeditationVisual playbackState="loading" variant="orb" size={100} />

        <h3 style={{ margin: 0, fontSize: '18px', color: 'var(--color-text-primary)' }}>
          Creating Your Meditation
        </h3>

        <p
          style={{
            margin: 0,
            fontSize: '14px',
            color: 'var(--color-wellness-lavender)',
            fontStyle: 'italic',
          }}
        >
          Marin is preparing your personalized session...
        </p>

        <div
          style={{
            width: '100%',
            maxWidth: '240px',
            height: '6px',
            background: 'var(--color-neutral-200)',
            borderRadius: '3px',
            overflow: 'hidden',
          }}
        >
          <div
            style={{
              width: '65%',
              height: '100%',
              background:
                'linear-gradient(90deg, var(--color-wellness-lavender), var(--color-wellness-sage))',
              borderRadius: '3px',
              transition: 'width 0.3s ease',
            }}
          />
        </div>

        <p style={{ margin: 0, fontSize: '14px', color: 'var(--color-text-muted)' }}>
          Streaming audio...
        </p>
      </div>

      <div
        style={{
          marginTop: '16px',
          padding: '8px 12px',
          background: 'var(--color-neutral-50)',
          borderRadius: '8px',
          textAlign: 'center',
        }}
      >
        <span style={{ fontSize: '14px', color: 'var(--color-text-secondary)' }}>
          üåø Anxiety Relief ‚Ä¢ 10 min
        </span>
      </div>
    </div>
  ),
  parameters: {
    docs: {
      description: {
        story: 'Simulated streaming state showing progress bar and voice personalization message.',
      },
    },
  },
};

/**
 * Error state simulation.
 */
export const ErrorState: Story = {
  render: () => (
    <div
      style={{
        padding: '32px',
        background: 'var(--color-exercise-card)',
        borderRadius: '12px',
        maxWidth: '400px',
        textAlign: 'center',
      }}
    >
      <div style={{ fontSize: '48px', marginBottom: '16px' }}>‚ö†Ô∏è</div>
      <h3 style={{ margin: '0 0 8px', fontSize: '18px', color: 'var(--color-text-primary)' }}>
        Generation Failed
      </h3>
      <p
        style={{
          margin: '0 0 24px',
          fontSize: '14px',
          color: 'var(--color-text-secondary)',
          maxWidth: '280px',
          marginLeft: 'auto',
          marginRight: 'auto',
        }}
      >
        Unable to generate meditation audio. Please try again.
      </p>
      <button
        style={{
          padding: '12px 24px',
          fontSize: '16px',
          fontWeight: 500,
          border: 'none',
          borderRadius: '8px',
          background:
            'linear-gradient(135deg, var(--color-wellness-lavender), var(--color-wellness-sage))',
          color: 'white',
          cursor: 'pointer',
        }}
      >
        Try Again
      </button>
    </div>
  ),
  parameters: {
    docs: {
      description: {
        story: 'Error state shown when audio generation fails.',
      },
    },
  },
};

/**
 * Completion state simulation.
 */
export const CompletionState: Story = {
  render: () => (
    <div
      style={{
        padding: '32px',
        background: 'var(--color-exercise-card)',
        borderRadius: '12px',
        maxWidth: '400px',
        textAlign: 'center',
      }}
    >
      <svg
        style={{
          width: '80px',
          height: '80px',
          color: 'var(--color-success)',
          marginBottom: '16px',
        }}
        viewBox="0 0 24 24"
        fill="none"
        stroke="currentColor"
        strokeWidth="2"
        strokeLinecap="round"
        strokeLinejoin="round"
      >
        <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14" />
        <polyline points="22 4 12 14.01 9 11.01" />
      </svg>
      <h3 style={{ margin: '0 0 8px', fontSize: '20px', color: 'var(--color-text-primary)' }}>
        Well Done!
      </h3>
      <p
        style={{
          margin: '0 0 16px',
          fontSize: '16px',
          color: 'var(--color-text-secondary)',
          maxWidth: '280px',
          marginLeft: 'auto',
          marginRight: 'auto',
          lineHeight: 1.5,
        }}
      >
        You completed your personalized 10-minute anxiety relief meditation.
      </p>
      <p style={{ margin: '0 0 8px', fontSize: '14px', color: 'var(--color-text-secondary)' }}>
        Mood: üòï Stressed ‚Üí üòå Relaxed
      </p>
      <p
        style={{
          margin: '0 0 24px',
          fontSize: '14px',
          color: 'var(--color-text-muted)',
          opacity: 0.7,
        }}
      >
        ‚ú® This meditation has been saved to your library
      </p>
      <button
        style={{
          padding: '10px 20px',
          fontSize: '14px',
          fontWeight: 500,
          border: 'none',
          borderRadius: '8px',
          background: 'var(--color-neutral-100)',
          color: 'var(--color-text-secondary)',
          cursor: 'pointer',
        }}
      >
        Meditate Again
      </button>
    </div>
  ),
  parameters: {
    docs: {
      description: {
        story: 'Completion state showing mood change and save confirmation.',
      },
    },
  },
};

// ==============================================================================
// Test Stories with Play Functions
// ==============================================================================

/**
 * Test: Start meditation flow
 */
export const TestStartMeditation: Story = {
  args: {
    activityData: createMockActivityData({
      audio_url: 'https://example.com/test.mp3', // Skip streaming for test
    }),
  },
  play: async ({ canvasElement }) => {
    const canvas = within(canvasElement);

    // Verify idle state elements
    await expect(canvas.getByText('Evening Calm')).toBeInTheDocument();
    await expect(canvas.getByText(/AI Generated/)).toBeInTheDocument();
    await expect(canvas.getByText('Begin Meditation')).toBeInTheDocument();
  },
};

/**
 * Test: Voice selection interaction
 */
export const TestVoiceSelection: StoryObj<typeof VoiceSelector> = {
  render: () => (
    <VoiceSelector voices={MOCK_VOICES} selectedVoiceId={null} onSelect={fn()} onConfirm={fn()} />
  ),
  play: async ({ canvasElement }) => {
    const canvas = within(canvasElement);

    // Verify all voices are shown (OpenAI voices)
    await expect(canvas.getByText('Marin')).toBeInTheDocument();
    await expect(canvas.getByText('Cedar')).toBeInTheDocument();
    await expect(canvas.getByText('Nova')).toBeInTheDocument();

    // Click on Cedar voice
    const cedarCard = canvas.getByTestId('voice-option-cedar');
    await userEvent.click(cedarCard);

    // Verify selection indicator
    await expect(cedarCard).toHaveAttribute('data-selected', 'true');
  },
};

// ==============================================================================
// Mobile View
// ==============================================================================

/**
 * Mobile responsive view
 */
export const MobileView: Story = {
  args: {
    activityData: createMockActivityData(),
  },
  parameters: {
    viewport: {
      defaultViewport: 'mobile1',
    },
    docs: {
      description: {
        story: 'AI-generated meditation at mobile viewport width.',
      },
    },
  },
};

/**
 * Mobile voice selector
 */
export const MobileVoiceSelector: StoryObj<typeof VoiceSelector> = {
  render: () => (
    <VoiceSelector voices={MOCK_VOICES} selectedVoiceId="marin" onSelect={fn()} onConfirm={fn()} />
  ),
  parameters: {
    viewport: {
      defaultViewport: 'mobile1',
    },
    docs: {
      description: {
        story: 'Voice selector at mobile viewport width.',
      },
    },
  },
};
